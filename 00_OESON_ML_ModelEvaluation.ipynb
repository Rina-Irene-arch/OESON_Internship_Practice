{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228beda7",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "1. Data Preparation\n",
    "\n",
    "Data preparation is like getting all the ingredients ready before cooking. It involves cleaning the data (removing or fixing any errors or missing values), normalizing or standardizing it (so all features have similar scales), and sometimes augmenting it (adding more data through transformations). For the MVTec AD dataset, this might include resizing images, converting them to grayscale or color, and ensuring that each image is labeled correctly.\n",
    "\n",
    "2. Train - Test Split\n",
    "\n",
    "This step involves dividing your dataset into two parts: one for training your model (train set) and one for testing it (test set). It's like studying for an exam using a portion of the material (training) and then testing your knowledge on a different set of questions (testing). Typically, 70-80% of the data is used for training, and the rest for testing. This helps in evaluating how well your model will perform on unseen data.\n",
    "\n",
    "3. Model Training\n",
    "\n",
    "Model training is where the magic happens. The training data is fed into the machine learning algorithm, which learns patterns and relationships within the data. This is similar to learning from examples and improving your skills over time. For anomaly detection, the model learns what normal (non-anomalous) data looks like, so it can identify what doesn’t fit that pattern.\n",
    "\n",
    "4. Model Evaluation using Metrics\n",
    "\n",
    "After training, you need to evaluate how well your model performs. This involves using metrics like accuracy, precision, recall, F1-score, etc. It’s like getting a report card that tells you how well you did. Each metric provides different insights:\n",
    "\n",
    "- **Accuracy**: How many predictions were correct overall.\n",
    "- **Precision**: Out of all the predicted anomalies, how many were actual anomalies. Higher precision means fewer false positives\n",
    "- **Recall**: true positive rate - Out of all actual anomalies, how many were correctly predicted. Higher recall means fewer false negatives\n",
    "- **F1-score**: A balance between precision and recall.\n",
    "\n",
    "5. Cross-Validation\n",
    "\n",
    "Cross-validation is a technique to make sure your model's performance is robust and not dependent on a particular train-test split. It involves dividing the data into multiple folds (subsets) and training/testing the model multiple times, each time with a different fold as the test set and the remaining folds as the training set. This is like taking multiple mock exams to ensure you're consistently good and not just lucky once.\n",
    "\n",
    "6. Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification model. It shows the counts of \n",
    "- **true positive** (correctly identified anomalies), \n",
    "- **true negative** (correctly identified normal data), \n",
    "- **false positive** (normal data incorrectly labeled as anomalies). (Type I error).\n",
    "- **false negative** (anomalies incorrectly labeled as normal). (Type II error).\n",
    "\n",
    "It’s a detailed report card that shows where the model is getting things right and where it’s making mistakes.\n",
    "\n",
    "7. Precision-Recall Curve\n",
    "\n",
    "The precision-recall curve is a graph that shows the trade-off between precision and recall for different threshold settings. Higher precision means fewer false positives, and higher recall means fewer false negatives. The curve helps in understanding the balance between precision and recall and finding an optimal threshold for your specific application.\n",
    "\n",
    "8. ROC Curve\n",
    "\n",
    "The ROC (Receiver Operating Characteristic) curve is another graph that shows the trade-off between true positive rate (recall) and false positive rate. The area under the ROC curve (AUC) provides a single measure of the model’s performance. A model with an AUC close to 1 indicates a good model, while an AUC close to 0.5 suggests a model no better than random guessing. It’s like a comprehensive score that tells you how well your model distinguishes between anomalies and normal data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06987e0b",
   "metadata": {},
   "source": [
    "1. Data Preparation \n",
    "2. Train - Test Split \n",
    "3. Model Training \n",
    "4. Model Evaluation using Metrics \n",
    "5. Cross - Validation \n",
    "6. Confuion Matrix \n",
    "7. Precision- Recall Curve \n",
    "8. ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03a2943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import(accuracy_score, precision_score, f1_score, confusion_matrix, \n",
    "                            precision_recall_curve,recall_score,\n",
    "                    roc_curve, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score)\n",
    "\n",
    "from sklearn.datasets import load_iris, fetch_california_housing\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a384bfe4",
   "metadata": {},
   "source": [
    "`load_boston` has been removed from scikit-learn since version 1.2.\n",
    "\n",
    "The Boston housing prices dataset has an ethical problem: as\n",
    "investigated in [1], the authors of this dataset engineered a\n",
    "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
    "positive impact on house prices [2]. Furthermore the goal of the\n",
    "research that led to the creation of this dataset was to study the\n",
    "impact of air quality but it did not give adequate demonstration of the\n",
    "validity of this assumption.\n",
    "\n",
    "The scikit-learn maintainers therefore strongly discourage the use of\n",
    "this dataset unless the purpose of the code is to study and educate\n",
    "about ethical issues in data science and machine learning.\n",
    "\n",
    "In this special case, you can fetch the dataset from the original\n",
    "source::\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "    target = raw_df.values[1::2, 2]\n",
    "\n",
    "Alternative datasets include the California housing dataset and the\n",
    "Ames housing dataset. You can load the datasets as follows::\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "for the California housing dataset and::\n",
    "\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    housing = fetch_openml(name=\"house_prices\", as_frame=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea9523",
   "metadata": {},
   "source": [
    "Regression Metrics: \n",
    "1. MSE \n",
    "2. MAE \n",
    "3. RMSE \n",
    "4. R2 score : value ranges between 0 and 1 \n",
    "\n",
    "\n",
    "Classification Metrics: \n",
    "1. Accuracy : values are correctly classified \n",
    "2. Precision: 10 - 5 M and 5 F - how many are relevant from selected  \n",
    "3. Recall(senstivity): how many relevants items are selected \n",
    "4. F1 - score: for imabalanced dataset - make balance precision and recall \n",
    "5. ROC (Receiver operating Characteristics) and AUC (Area Under Curve): 0.5 to 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e666d56",
   "metadata": {},
   "source": [
    "## 2. Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e79fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRIS DATASET\n",
    "# Train - Test Split \n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, \n",
    "                                                                        test_size=0.2, \n",
    "                                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9dfd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOUSING DATASET \n",
    "#Train - Test Split \n",
    "house = fetch_california_housing()\n",
    "X_house = house.data\n",
    "y_house = house.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train_house, X_test_house, y_train_house, y_test_house = train_test_split(X_house, \n",
    "                                                                                y_house, \n",
    "                                                                                test_size=0.2,\n",
    "                                                                                random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec19af",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad953cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_iris = clf.predict(X_test_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_house, y_train_house)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_house = reg.predict(X_test_house)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d6d3f",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation using Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6f980",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "1. **Accuracy**\n",
    "- Definition: The ratio of correctly predicted instances to the total number of instances.\n",
    "- Use: Good for balanced datasets but can be misleading if classes are imbalanced.\n",
    "\n",
    "2. **Precision**\n",
    "- Definition: The ratio of true positive predictions to the total number of positive predictions (true positives + false positives).\n",
    "- Use: Important when the cost of false positives is high, such as in spam detection.\n",
    "\n",
    "3. **Recall (Sensitivity, True Positive Rate)**\n",
    "- Definition: The ratio of true positive predictions to the total number of actual positives (true positives + false negatives).\n",
    "- Use: Crucial when missing positive instances is costly, such as in medical diagnoses.\n",
    "\n",
    "4. **F1-Score**\n",
    "- Definition: The harmonic mean of precision and recall. It balances both metrics and provides a single score.\n",
    "- Use: Useful when you need a balance between precision and recall.\n",
    "\n",
    "5. **Confusion matrix**\n",
    "- Definition: A table showing the counts of true positives, true negatives, false positives, and false negatives.\n",
    "- Use: Helps visualize performance and understand where the model makes errors.\n",
    "\n",
    "6. **ROC Curve and AUC**\n",
    "- ROC Curve: A graph plotting the true positive rate (recall) against the false positive rate at various threshold settings.\n",
    "- AUC (Area Under Curve): The area under the ROC curve, which summarizes the model’s ability to distinguish between classes. An AUC close to 1 indicates a good model.\n",
    "\n",
    "7. **Precision-Recall Curve**\n",
    "- PR Curve: A graph showing the trade-off between precision and recall for different threshold settings.\n",
    "- Use: Especially useful for imbalanced datasets to evaluate the model’s performance across different levels of precision and recall.\n",
    "\n",
    "### Regression Metrics\n",
    "- Regression metrics are used to evaluate models that predict continuous outcomes (e.g., predicting house prices). Here are some common metrics:\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**\n",
    "- Definition: The average absolute differences between predicted and actual values.\n",
    "- Use: Gives a straightforward measure of prediction accuracy in the same units as the target variable.\n",
    "\n",
    "2. **Mean Squared Error (MSE)**\n",
    "- Definition: The average of the squared differences between predicted and actual values.\n",
    "- Use: Penalizes larger errors more heavily due to squaring, making it sensitive to outliers.\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**\n",
    "- Definition: The square root of the mean squared error. It brings the error measure back to the same units as the target variable.\n",
    "- Use: Useful when you need to understand the magnitude of prediction errors in the same units as the target variable.\n",
    "\n",
    "4. **R-Squared (R²)**\n",
    "- Definition: The proportion of variance in the target variable that is predictable from the features.\n",
    "- Use: Indicates how well the model explains the variability of the target variable. R² values range from 0 to 1, with higher values indicating better model performance.\n",
    "\n",
    "5. **Adjusted R-Squared**\n",
    "- Definition: A modified version of R² that adjusts for the number of predictors in the model.\n",
    "- Use: Useful for comparing models with different numbers of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1314e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Classification Metrics \n",
    "\n",
    "accuracy = accuracy_score(y_test_iris,y_pred_iris)\n",
    "precision = precision_score(y_test_iris,y_pred_iris, average = 'weighted')\n",
    "recall = recall_score(y_test_iris,y_pred_iris, average = 'weighted')\n",
    "f1 = f1_score(y_test_iris,y_pred_iris, average = 'weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {accuracy}\")\n",
    "print(f\"Recall: {accuracy}\")\n",
    "print(f\"F1: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d09a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.555891598695242\n",
      "RMSE: 0.7455813830127748\n",
      "MAE: 0.5332001304956981\n",
      "R2: 0.5757877060324526\n"
     ]
    }
   ],
   "source": [
    "#Regression Metrics \n",
    "\n",
    "mse = mean_squared_error(y_test_house,y_pred_house)\n",
    "rmse = mean_squared_error(y_test_house,y_pred_house, squared = False)\n",
    "mae = mean_absolute_error(y_test_house,y_pred_house)\n",
    "r2 = r2_score(y_test_house,y_pred_house)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa489cf0",
   "metadata": {},
   "source": [
    "## 5. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de83222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Mean CV Score: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "#Classification CV \n",
    "\n",
    "cv_score = cross_val_score(clf, X_iris, y_iris, cv=5)\n",
    "print(f\"Cross Validation Score: {cv_score}\")\n",
    "print(f\"Mean CV Score: {cv_score.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca3aef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Regression Score: [-0.48485857 -0.62249739 -0.64621047 -0.5431996  -0.49468484]\n",
      "Mean Regression CV Score: -0.5582901717686809\n"
     ]
    }
   ],
   "source": [
    "#Regression CV \n",
    "\n",
    "cv_scores = cross_val_score(reg, X_house, y_house, cv=5, scoring = 'neg_mean_squared_error')\n",
    "print(f\"Cross Validation Regression Score: {cv_scores}\")\n",
    "print(f\"Mean Regression CV Score: {cv_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa73565",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix\n",
    "\n",
    "- True Positive (TP): Correctly predicted positive instances.\n",
    "- True Negative (TN): Correctly predicted negative instances.\n",
    "- False Positive (FP): Incorrectly predicted positive instances (Type I error).\n",
    "- False Negative (FN): Incorrectly predicted negative instances (Type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6927d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Classification \n",
    "cm = confusion_matrix(y_test_iris, y_pred_iris)\n",
    "sns.heatmap(cm, annot= True, fmt = 'd', cmap = 'Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5cb11c",
   "metadata": {},
   "source": [
    "## 7. Precision_Recall_Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f0c23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict the probabilities for positive class \n",
    "y_scores = clf.predict_proba(X_test_iris)[:, 1]\n",
    "\n",
    "#P-R pair for different threshold \n",
    "pre, recall, thresholds = precision_recall_curve(y_test_iris, y_scores, pos_label=1)\n",
    "\n",
    "\n",
    "plt.plot(thresholds, pre[:-1], 'b--', label = \"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], 'g-', label = \"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Precision_Recall_Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3420206",
   "metadata": {},
   "source": [
    "The Precision-Recall curve provides insight into the performance of a classification model, especially in situations where class imbalance is present. In your plot for the Iris dataset, we can deduce the following:\n",
    "\n",
    "Precision: The dashed blue line represents precision. In this plot, precision appears to stay constant at around 1.0 (or very close to it) across different threshold values. This suggests that when the model predicts the positive class, it is almost always correct.\n",
    "\n",
    "Recall: The solid green line represents recall. Recall starts high and gradually decreases as the threshold increases. This indicates that the model initially identifies most of the positive instances but starts missing them as the threshold for classifying an instance as positive increases.\n",
    "\n",
    "Threshold: The x-axis represents different threshold values. As the threshold increases, fewer instances are classified as positive, which typically decreases recall and may affect precision.\n",
    "\n",
    "Trade-off: The plot illustrates the trade-off between precision and recall. To achieve high recall, the threshold is low, capturing more true positives but potentially including more false positives. Conversely, a higher threshold improves precision but reduces recall as fewer positives are identified.\n",
    "\n",
    "For the Iris dataset:\n",
    "\n",
    "If your goal is to minimize false negatives (e.g., you care more about capturing all positive instances), you might choose a lower threshold, accepting some false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3cda4c",
   "metadata": {},
   "source": [
    "\n",
    "8. ROC Curve\n",
    "\n",
    "The ROC (Receiver Operating Characteristic) curve is another graph that shows the trade-off between true positive rate (recall) and false positive rate. The area under the ROC curve (AUC) provides a single measure of the model’s performance. A model with an AUC close to 1 indicates a good model, while an AUC close to 0.5 suggests a model no better than random guessing. It’s like a comprehensive score that tells you how well your model distinguishes between anomalies and normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b483a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
